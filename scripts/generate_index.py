import os
import json
import xml.etree.ElementTree as ET
import requests
import glob
import datetime

# é…ç½®
BLUEPRINTS_DIR = "blueprints"
OUTPUT_FILE = "index.json"
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY") # å¿…é¡»æ˜¯ Service Role Key

def parse_size(size_str):
    """è§£æ '(13,13)' æ ¼å¼çš„å­—ç¬¦ä¸²"""
    try:
        clean = size_str.replace('(', '').replace(')', '')
        parts = clean.split(',')
        return int(parts[0]), int(parts[1])
    except:
        return 0, 0

def parse_blueprint_xml(file_path):
    """è§£æå•ä¸ª XML æ–‡ä»¶"""
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        
        # æŸ¥æ‰¾ extraInfo èŠ‚ç‚¹
        extra_info = root.find("extraInfo")
        if extra_info is None:
            print(f"Skipping {file_path}: No <extraInfo> found.")
            return None
            
        # æå–å­—æ®µ
        def get_text(node, tag, default=""):
            child = node.find(tag)
            return child.text if child is not None else default

        building_id = get_text(extra_info, "BuildingID")
        if not building_id:
            print(f"Warning {file_path}: No <BuildingID> found.")
            return None

        name = get_text(extra_info, "name", "Unnamed")
        author = get_text(extra_info, "author", "Unknown")
        category = get_text(extra_info, "category", "Uncategorized")
        version = get_text(extra_info, "version", "1.0")
        tags = get_text(extra_info, "tags", "")
        
        # æå– Size
        size_node = root.find("size")
        width, height = (0, 0)
        if size_node is not None:
            width, height = parse_size(size_node.text)

        # æå– Mods
        mods = []
        mod_packages = extra_info.find("modPackages")
        if mod_packages is not None:
            for mod in mod_packages.findall("mod"):
                pkg_id = mod.find("packageId")
                if pkg_id is not None and pkg_id.text:
                    mods.append(pkg_id.text)
        
        # ç›¸å¯¹è·¯å¾„ (ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ )
        # file_path å¯èƒ½æ˜¯ "blueprints\subdir\file.xml"
        relative_path = file_path.replace("\\", "/")
        
        return {
            "id": building_id,
            "n": name,
            "a": author,
            "c": category,
            "v": version,
            "t": tags,
            "w": width,
            "h": height,
            "m": mods,
            "p": relative_path
        }
    except Exception as e:
        print(f"Error parsing {file_path}: {e}")
        return None

def sync_to_supabase(blueprints_data):
    """åŒæ­¥åˆ° Supabase"""
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("Supabase credentials not found. Skipping sync.")
        return

    print(f"Syncing {len(blueprints_data)} blueprints to Supabase...")
    
    db_payload = []
    for bp in blueprints_data:
        # æ³¨æ„ï¼šè¿™é‡ŒåªåŒæ­¥å…ƒæ•°æ®å­—æ®µï¼Œä¸å« mod ä¾èµ–åˆ—è¡¨ç­‰å¤æ‚ç»“æ„ï¼Œ
        # å¤æ‚ç»“æ„é€šå¸¸åªåœ¨ json é‡Œï¼Œæˆ–è€…éœ€è¦å…³è”è¡¨ã€‚
        # æˆ‘ä»¬çš„æ•°æ®åº“è®¾è®¡ä¸­ mod_dependencies æ˜¯å¦ä¸€å¼ è¡¨ã€‚
        # ç®€å•èµ·è§ï¼Œè¿™é‡Œåªæ›´æ–° blueprints ä¸»è¡¨ã€‚
        db_payload.append({
            "id": bp["id"],
            "name": bp["n"],
            "author": bp["a"],
            "category": bp["c"],
            "version": bp["v"],
            "tags": bp["t"],
            "width": bp["w"],
            "height": bp["h"],
            "github_path": bp["p"]
        })
    
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates" # Upsert ç­–ç•¥
    }
    
    # åˆ†æ‰¹å‘é€
    batch_size = 50
    for i in range(0, len(db_payload), batch_size):
        batch = db_payload[i:i+batch_size]
        url = f"{SUPABASE_URL}/rest/v1/blueprints"
        try:
            resp = requests.post(url, headers=headers, json=batch)
            if resp.status_code >= 400:
                print(f"Batch {i//batch_size + 1} Error: {resp.text}")
            else:
                print(f"Batch {i//batch_size + 1} Success.")
        except Exception as e:
            print(f"Network error: {e}")

def main():
    print("Starting index generation...")
    all_blueprints = []

    # ğŸ”¥ ä¼˜å…ˆä»æ•°æ®åº“è·å–æ•°æ®ï¼ˆæ¨èæ–¹å¼ï¼‰
    if SUPABASE_URL and SUPABASE_KEY:
        print("Fetching blueprints from database...")
        try:
            headers = {
                "apikey": SUPABASE_KEY,
                "Authorization": f"Bearer {SUPABASE_KEY}",
                "Content-Type": "application/json"
            }

            # åªè·å–æœ‰æ•ˆä¸”æ´»è·ƒçš„è®°å½•
            url = f"{SUPABASE_URL}/rest/v1/blueprints?select=id,name,author,category,tags,width,height,github_path,version,created_at&is_active=eq.true"
            response = requests.get(url, headers=headers)

            if response.status_code == 200:
                db_blueprints = response.json()
                print(f"Found {len(db_blueprints)} blueprints in database")

                if len(db_blueprints) > 0:
                    # æ•°æ®åº“ä¸­æ‰¾åˆ°è“å›¾ï¼ŒåŒæ—¶éªŒè¯æ–‡ä»¶ç³»ç»Ÿ
                    scan_from_filesystem_with_validation(all_blueprints, db_blueprints)
                    return  # å®Œæˆï¼Œä¸éœ€è¦ç»§ç»­
                else:
                    print("No blueprints found in database, falling back to file system scan...")
                    # æ•°æ®åº“å®Œå…¨ä¸ºç©ºï¼Œæ‰§è¡Œé»˜è®¤æ“ä½œ
                    scan_from_filesystem(all_blueprints)
            else:
                print(f"Failed to fetch from database: {response.status_code} - {response.text}")
                print("Falling back to file system scan...")
                # å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°æ–‡ä»¶æ‰«æ
                scan_from_filesystem(all_blueprints)
        except Exception as e:
            print(f"Database fetch error: {e}")
            print("Falling back to file system scan...")
            # å¦‚æœå‡ºé”™ï¼Œå›é€€åˆ°æ–‡ä»¶æ‰«æ
            scan_from_filesystem(all_blueprints)
    else:
        print("No Supabase credentials found, scanning from file system...")
        scan_from_filesystem(all_blueprints)

def scan_from_filesystem_with_validation(all_blueprints, db_blueprints):
    """æ‰«ææ–‡ä»¶ç³»ç»Ÿå¹¶éªŒè¯æ•°æ®åº“ä¸­çš„è“å›¾å­˜åœ¨æ–‡ä»¶"""
    # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æœ‰æ•ˆçš„blueprint ID
    valid_blueprint_ids = {bp["id"] for bp in db_blueprints}
    print(f"Database has {len(valid_blueprint_ids)} valid blueprint IDs")

    # æ‰«ææ–‡ä»¶ç³»ç»Ÿ
    search_path = os.path.join(BLUEPRINTS_DIR, "**/*.xml")
    files = glob.glob(search_path, recursive=True)
    files = [f for f in files if '.cleanup' not in f]

    print(f"Found {len(files)} XML files in {BLUEPRINTS_DIR} (excluding .cleanup)")

    # ç»Ÿè®¡ä¿¡æ¯
    valid_count = 0
    orphaned_count = 0

    # 1. é¦–å…ˆæ·»åŠ æ•°æ®åº“ä¸­çš„è“å›¾ï¼ˆæ— è®ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼‰
    for bp in db_blueprints:
        if bp.get("id") and bp.get("name"):
            all_blueprints.append({
                "id": bp["id"],
                "n": bp["name"],
                "a": bp.get("author", "Unknown"),
                "c": bp.get("category", "Custom"),
                "v": bp.get("version", "1.0"),
                "t": bp.get("tags", ""),
                "w": bp.get("width", 0),
                "h": bp.get("height", 0),
                "m": [], # ä»æ•°æ®åº“æ— æ³•ç›´æ¥è·å–modä¾èµ–ï¼Œæš‚æ—¶ä¸ºç©º
                "p": bp.get("github_path", f"blueprints/{bp['id']}.xml")
            })
            valid_count += 1

    # 2. æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„å­¤å„¿æ–‡ä»¶å¹¶æŠ¥å‘Š
    for f in files:
        data = parse_blueprint_xml(f)
        if data and data["id"] not in valid_blueprint_ids:
            print(f"âš ï¸  Orphaned file: {f} (Blueprint ID: {data['id']})")
            orphaned_count += 1

    print(f"âœ… Added {valid_count} valid blueprints from database")
    if orphaned_count > 0:
        print(f"âš ï¸  Found {orphaned_count} orphaned files (not included in index)")

    # ç”Ÿæˆ index.json
    output_data = {
        "version": "1.0",
        "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
        "blueprints": all_blueprints,
        "generation_stats": {
            "strategy": "database_with_file_validation",
            "database_blueprints": valid_count,
            "orphaned_files_found": orphaned_count,
            "total_files_scanned": len(files),
            "message": "Database-driven with orphaned file detection"
        }
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, separators=(',', ':'))

    print(f"Generated {OUTPUT_FILE} with {len(all_blueprints)} entries (database validated).")

    # ç”Ÿæˆå­¤å„¿æ–‡ä»¶æŠ¥å‘Š
    if orphaned_count > 0:
        generate_orphaned_report(files, valid_blueprint_ids)

def scan_from_filesystem(all_blueprints):
    """ä»æ–‡ä»¶ç³»ç»Ÿæ‰«æXMLæ–‡ä»¶ï¼ˆé»˜è®¤æ“ä½œæ–¹å¼ï¼‰"""
    # æŸ¥æ‰¾æ‰€æœ‰ xml æ–‡ä»¶
    # ä½¿ç”¨ glob é€’å½’æŸ¥æ‰¾ blueprints ç›®å½•
    search_path = os.path.join(BLUEPRINTS_DIR, "**/*.xml")
    files = glob.glob(search_path, recursive=True)

    # ğŸ†• æ’é™¤.cleanupç›®å½•ä¸­çš„æ–‡ä»¶
    files = [f for f in files if '.cleanup' not in f]

    print(f"Found {len(files)} XML files in {BLUEPRINTS_DIR} (excluding .cleanup)")

    # é»˜è®¤æ“ä½œï¼šåŒ…å«æ‰€æœ‰æ–‡ä»¶
    for f in files:
        data = parse_blueprint_xml(f)
        if data:
            all_blueprints.append(data)

    # ç”Ÿæˆ index.json
    output_data = {
        "version": "1.0",
        "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
        "blueprints": all_blueprints,
        "generation_stats": {
            "strategy": "filesystem_default",
            "total_files_scanned": len(files),
            "total_blueprints": len(all_blueprints),
            "message": "Database empty or unavailable - including all files"
        }
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, separators=(',', ':'))

    print(f"Generated {OUTPUT_FILE} with {len(all_blueprints)} entries (default filesystem scan).")

    # åŒæ­¥æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
    sync_to_supabase(all_blueprints)

def generate_orphaned_report(files, valid_blueprint_ids):
    """ç”Ÿæˆå­¤å„¿æ–‡ä»¶æŠ¥å‘Š"""
    orphaned_files = []

    for f in files:
        data = parse_blueprint_xml(f)
        if data and data["id"] not in valid_blueprint_ids:
            orphaned_files.append({
                "file": f,
                "blueprint_id": data["id"],
                "name": data["n"],
                "author": data["a"]
            })

    if orphaned_files:
        report_data = {
            "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
            "orphaned_count": len(orphaned_files),
            "orphaned_files": orphaned_files,
            "message": "These files exist in filesystem but not in database (consider running cleanup)"
        }

        with open('orphaned_blueprints_report.json', 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"Generated orphaned files report: orphaned_blueprints_report.json")

if __name__ == "__main__":
    main()
