import os
import json
import xml.etree.ElementTree as ET
import requests
import glob
import datetime

# é…ç½®
BLUEPRINTS_DIR = "blueprints"
OUTPUT_FILE = "index.json"
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY") # å¿…é¡»æ˜¯ Service Role Key

def parse_size(size_str):
    """è§£æ '(13,13)' æ ¼å¼çš„å­—ç¬¦ä¸²"""
    try:
        clean = size_str.replace('(', '').replace(')', '')
        parts = clean.split(',')
        return int(parts[0]), int(parts[1])
    except:
        return 0, 0

def parse_blueprint_xml(file_path):
    """è§£æå•ä¸ª XML æ–‡ä»¶"""
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        
        # æŸ¥æ‰¾ extraInfo èŠ‚ç‚¹
        extra_info = root.find("extraInfo")
        if extra_info is None:
            print(f"Skipping {file_path}: No <extraInfo> found.")
            return None
            
        # æå–å­—æ®µ
        def get_text(node, tag, default=""):
            child = node.find(tag)
            return child.text if child is not None else default

        building_id = get_text(extra_info, "BuildingID")
        if not building_id:
            print(f"Warning {file_path}: No <BuildingID> found.")
            return None

        name = get_text(extra_info, "name", "Unnamed")
        author = get_text(extra_info, "author", "Unknown")
        category = get_text(extra_info, "category", "Uncategorized")
        version = get_text(extra_info, "version", "1.0")
        tags = get_text(extra_info, "tags", "")
        
        # æå– Size
        size_node = root.find("size")
        width, height = (0, 0)
        if size_node is not None:
            width, height = parse_size(size_node.text)

        # æå– Mods
        mods = []
        mod_packages = extra_info.find("modPackages")
        if mod_packages is not None:
            for mod in mod_packages.findall("mod"):
                pkg_id = mod.find("packageId")
                if pkg_id is not None and pkg_id.text:
                    mods.append(pkg_id.text)
        
        # ç›¸å¯¹è·¯å¾„ (ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ )
        # file_path å¯èƒ½æ˜¯ "blueprints\subdir\file.xml"
        relative_path = file_path.replace("\\", "/")
        
        return {
            "id": building_id,
            "n": name,
            "a": author,
            "c": category,
            "v": version,
            "t": tags,
            "w": width,
            "h": height,
            "m": mods,
            "p": relative_path
        }
    except Exception as e:
        print(f"Error parsing {file_path}: {e}")
        return None

def sync_to_supabase(blueprints_data):
    """åŒæ­¥åˆ° Supabase"""
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("Supabase credentials not found. Skipping sync.")
        return

    print(f"Syncing {len(blueprints_data)} blueprints to Supabase...")
    
    db_payload = []
    for bp in blueprints_data:
        # æ³¨æ„ï¼šè¿™é‡ŒåªåŒæ­¥å…ƒæ•°æ®å­—æ®µï¼Œä¸å« mod ä¾èµ–åˆ—è¡¨ç­‰å¤æ‚ç»“æ„ï¼Œ
        # å¤æ‚ç»“æ„é€šå¸¸åªåœ¨ json é‡Œï¼Œæˆ–è€…éœ€è¦å…³è”è¡¨ã€‚
        # æˆ‘ä»¬çš„æ•°æ®åº“è®¾è®¡ä¸­ mod_dependencies æ˜¯å¦ä¸€å¼ è¡¨ã€‚
        # ç®€å•èµ·è§ï¼Œè¿™é‡Œåªæ›´æ–° blueprints ä¸»è¡¨ã€‚
        db_payload.append({
            "id": bp["id"],
            "name": bp["n"],
            "author": bp["a"],
            "category": bp["c"],
            "version": bp["v"],
            "tags": bp["t"],
            "width": bp["w"],
            "height": bp["h"],
            "github_path": bp["p"]
        })
    
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates" # Upsert ç­–ç•¥
    }
    
    # åˆ†æ‰¹å‘é€
    batch_size = 50
    for i in range(0, len(db_payload), batch_size):
        batch = db_payload[i:i+batch_size]
        url = f"{SUPABASE_URL}/rest/v1/blueprints"
        try:
            resp = requests.post(url, headers=headers, json=batch)
            if resp.status_code >= 400:
                print(f"Batch {i//batch_size + 1} Error: {resp.text}")
            else:
                print(f"Batch {i//batch_size + 1} Success.")
        except Exception as e:
            print(f"Network error: {e}")

def main():
    print("Starting index generation...")
    all_blueprints = []

    # ğŸ”¥ ä¼˜å…ˆä»æ•°æ®åº“è·å–æ•°æ®ï¼ˆæ¨èæ–¹å¼ï¼‰
    if SUPABASE_URL and SUPABASE_KEY:
        print("Fetching blueprints from database...")
        try:
            headers = {
                "apikey": SUPABASE_KEY,
                "Authorization": f"Bearer {SUPABASE_KEY}",
                "Content-Type": "application/json"
            }

            # åªè·å–æœ‰æ•ˆï¼ˆæœ‰BuildingIDï¼‰çš„è®°å½•
            url = f"{SUPABASE_URL}/rest/v1/blueprints?select=id,name,author,category,tags,width,height,github_path,version,created_at"
            response = requests.get(url, headers=headers)

            if response.status_code == 200:
                db_blueprints = response.json()
                print(f"Found {len(db_blueprints)} blueprints in database")

                for bp in db_blueprints:
                    if bp.get("id") and bp.get("name"):
                        all_blueprints.append({
                            "id": bp["id"],
                            "n": bp["name"],
                            "a": bp.get("author", "Unknown"),
                            "c": bp.get("category", "Custom"),
                            "v": bp.get("version", "1.0"),
                            "t": bp.get("tags", ""),
                            "w": bp.get("width", 0),
                            "h": bp.get("height", 0),
                            "m": [], # ä»æ•°æ®åº“æ— æ³•ç›´æ¥è·å–modä¾èµ–ï¼Œæš‚æ—¶ä¸ºç©º
                            "p": bp.get("github_path", f"blueprints/{bp['id']}.xml")
                        })
                print(f"Successfully processed {len(all_blueprints)} blueprints from database")
            else:
                print(f"Failed to fetch from database: {response.status_code} - {response.text}")
                print("Falling back to file system scan...")
                # å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°æ–‡ä»¶æ‰«æ
                scan_from_filesystem(all_blueprints)
        except Exception as e:
            print(f"Database fetch error: {e}")
            print("Falling back to file system scan...")
            # å¦‚æœå‡ºé”™ï¼Œå›é€€åˆ°æ–‡ä»¶æ‰«æ
            scan_from_filesystem(all_blueprints)
    else:
        print("No Supabase credentials found, scanning from file system...")
        scan_from_filesystem(all_blueprints)

def scan_from_filesystem(all_blueprints):
    """ä»æ–‡ä»¶ç³»ç»Ÿæ‰«æXMLæ–‡ä»¶ï¼ˆåŸå§‹æ–¹å¼ï¼‰"""
    # æŸ¥æ‰¾æ‰€æœ‰ xml æ–‡ä»¶
    # ä½¿ç”¨ glob é€’å½’æŸ¥æ‰¾ blueprints ç›®å½•
    search_path = os.path.join(BLUEPRINTS_DIR, "**/*.xml")
    files = glob.glob(search_path, recursive=True)

    # ğŸ†• æ’é™¤.cleanupç›®å½•ä¸­çš„æ–‡ä»¶
    files = [f for f in files if '.cleanup' not in f]

    print(f"Found {len(files)} XML files in {BLUEPRINTS_DIR} (excluding .cleanup)")

    if SUPABASE_URL and SUPABASE_KEY:
        # ğŸ†• æ–°ç­–ç•¥ï¼šåªæ·»åŠ æ•°æ®åº“ä¸­å­˜åœ¨çš„è“å›¾
        print("Using database existence validation strategy...")

        headers = {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json"
        }

        # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æœ‰æ•ˆçš„blueprint ID
        db_url = f"{SUPABASE_URL}/rest/v1/blueprints?select=id,is_active"
        db_response = requests.get(db_url, headers=headers)

        if db_response.status_code == 200:
            db_blueprints = db_response.json()
            valid_blueprint_ids = {
                bp["id"] for bp in db_blueprints
                if bp.get("is_active", True)  # åªåŒ…å«æ´»è·ƒçš„è“å›¾
            }

            print(f"Found {len(valid_blueprint_ids)} valid blueprint IDs in database")

            # åªå¤„ç†æ•°æ®åº“ä¸­å­˜åœ¨çš„æ–‡ä»¶
            valid_count = 0
            invalid_count = 0

            for f in files:
                data = parse_blueprint_xml(f)
                if data:
                    # æ£€æŸ¥è¿™ä¸ªblueprintæ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨ä¸”æ´»è·ƒ
                    if data["id"] in valid_blueprint_ids:
                        all_blueprints.append(data)
                        valid_count += 1
                    else:
                        print(f"âš ï¸  Skipping {f}: Blueprint ID {data['id']} not found in database or inactive")
                        invalid_count += 1

            print(f"âœ… Added {valid_count} valid blueprints to index")
            print(f"âŒ Skipped {invalid_count} invalid blueprints")

            # ç”ŸæˆåŒ…å«è­¦å‘Šä¿¡æ¯çš„index.json
            output_data = {
                "version": "1.0",
                "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
                "blueprints": all_blueprints,
                "generation_stats": {
                    "total_files_scanned": len(files),
                    "valid_blueprints": valid_count,
                    "skipped_blueprints": invalid_count,
                    "strategy": "database_validated",
                    "excluded_cleanup_files": True
                }
            }

            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, separators=(',', ':'))

            print(f"Generated {OUTPUT_FILE} with {len(all_blueprints)} entries (database validated).")

            # ä¸å†åŒæ­¥åˆ°æ•°æ®åº“ï¼Œå› ä¸ºæ•°æ®å·²ç»å­˜åœ¨
            print("Skipping database sync (data already exists)")

            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
            if invalid_count > 0:
                generate_skip_report(files, valid_blueprint_ids)

        else:
            print(f"Failed to fetch database data: {db_response.status_code} - {db_response.text}")
            print("Falling back to filesystem scanning without validation...")
            # å›é€€åˆ°åŸå§‹æ–¹å¼
            fallback_scan(files, all_blueprints)
    else:
        print("No Supabase credentials found, using filesystem scanning...")
        fallback_scan(files, all_blueprints)

def fallback_scan(files, all_blueprints):
    """å›é€€åˆ°åŸå§‹çš„æ–‡ä»¶ç³»ç»Ÿæ‰«ææ–¹å¼"""
    for f in files:
        data = parse_blueprint_xml(f)
        if data:
            all_blueprints.append(data)

    # ç”Ÿæˆ index.json
    output_data = {
        "version": "1.0",
        "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
        "blueprints": all_blueprints,
        "generation_stats": {
            "strategy": "filesystem_only",
            "warning": "No database validation performed"
        }
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, separators=(',', ':'))

    print(f"Generated {OUTPUT_FILE} with {len(all_blueprints)} entries (filesystem only).")

    # åŒæ­¥æ•°æ®åº“
    sync_to_supabase(all_blueprints)

def generate_skip_report(files, valid_blueprint_ids):
    """ç”Ÿæˆè·³è¿‡æ–‡ä»¶çš„æŠ¥å‘Š"""
    skipped_files = []

    for f in files:
        data = parse_blueprint_xml(f)
        if data and data["id"] not in valid_blueprint_ids:
            skipped_files.append({
                "file": f,
                "blueprint_id": data["id"],
                "name": data["n"],
                "author": data["a"]
            })

    if skipped_files:
        report_data = {
            "generated_at": datetime.datetime.utcnow().isoformat() + "Z",
            "skipped_count": len(skipped_files),
            "skipped_files": skipped_files,
            "message": "These files were not included in index.json because they don't exist in database or are inactive"
        }

        with open('skipped_blueprints_report.json', 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"Generated skipped files report: skipped_blueprints_report.json")

if __name__ == "__main__":
    main()
