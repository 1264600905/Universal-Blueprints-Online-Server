#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†å­¤å„¿æ–‡ä»¶è„šæœ¬
åˆ é™¤GitHubä»“åº“ä¸­å­˜åœ¨ä½†æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„è“å›¾æ–‡ä»¶
åŒæ—¶ç®¡ç† .cleanup ç›®å½•ï¼Œè‡ªåŠ¨æ¸…ç†è¶…è¿‡7å¤©çš„å¤‡ä»½å’Œæ—¥å¿—
"""

import os
import sys
import json
import glob
import requests
import xml.etree.ElementTree as ET
import datetime
import subprocess
import time
import shutil

# é…ç½®
BLUEPRINTS_DIR = "blueprints"
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

# æ¸…ç†ç›®å½•é…ç½®
CLEANUP_ROOT = ".cleanup"
CLEANUP_BLUEPRINTS_DIR = os.path.join(CLEANUP_ROOT, "blueprints")
CLEANUP_IMAGES_DIR = os.path.join(CLEANUP_ROOT, "images")
CLEANUP_REPORTS_DIR = os.path.join(CLEANUP_ROOT, "reports")
RETENTION_DAYS = 7  # å¤‡ä»½æ–‡ä»¶ä¿ç•™å¤©æ•°

class OrphanedFileCleaner:
    def __init__(self, supabase_url, supabase_key):
        self.supabase_url = supabase_url.rstrip('/')
        self.supabase_key = supabase_key
        self.headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json"
        }

    def prune_old_cleanup_files(self, dry_run=True):
        """
        æ¸…ç† .cleanup ç›®å½•ä¸‹è¶…è¿‡ RETENTION_DAYS å¤©çš„æ–‡ä»¶
        """
        print(f"ğŸ§¹ Checking for cleanup files older than {RETENTION_DAYS} days in {CLEANUP_ROOT}...")
        
        if not os.path.exists(CLEANUP_ROOT):
            print("  .cleanup directory does not exist yet. Skipping prune.")
            return

        now = time.time()
        cutoff = now - (RETENTION_DAYS * 86400)
        deleted_count = 0

        # éå† .cleanup ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        for root, dirs, files in os.walk(CLEANUP_ROOT):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    file_mtime = os.path.getmtime(file_path)
                    
                    if file_mtime < cutoff:
                        if dry_run:
                            print(f"  [Dry Run] Would delete old backup/log: {file_path}")
                        else:
                            os.remove(file_path)
                            print(f"  Deleted old backup/log: {file_path}")
                        deleted_count += 1
                except Exception as e:
                    print(f"  Error accessing {file_path}: {e}")

        # å°è¯•æ¸…ç†ç©ºæ–‡ä»¶å¤¹ (ä»…åœ¨édry_runæ¨¡å¼ä¸‹)
        if not dry_run:
            for root, dirs, files in os.walk(CLEANUP_ROOT, topdown=False):
                for name in dirs:
                    try:
                        dir_path = os.path.join(root, name)
                        if not os.listdir(dir_path):  # å¦‚æœç›®å½•ä¸ºç©º
                            os.rmdir(dir_path)
                            print(f"  Removed empty directory: {dir_path}")
                    except:
                        pass

        if deleted_count == 0:
            print("  No old files found to prune.")
        else:
            action = "Would delete" if dry_run else "Deleted"
            print(f"  {action} {deleted_count} old files.")
        print()

    def get_valid_blueprint_ids(self):
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰æœ‰æ•ˆçš„blueprint ID"""
        try:
            url = f"{self.supabase_url}/rest/v1/blueprints?select=id,is_active"
            response = requests.get(url, headers=self.headers)

            if response.status_code == 200:
                blueprints = response.json()
                valid_ids = {
                    bp["id"] for bp in blueprints
                    if bp.get("is_active", True)
                }
                print(f"Found {len(valid_ids)} valid blueprint IDs in database")
                return valid_ids
            else:
                print(f"Failed to fetch database data: {response.status_code}")
                return None

        except Exception as e:
            print(f"Error fetching valid blueprint IDs: {e}")
            return None

    def scan_local_files(self):
        """æ‰«ææœ¬åœ°çš„XMLæ–‡ä»¶"""
        search_path = os.path.join(BLUEPRINTS_DIR, "**/*.xml")
        files = glob.glob(search_path, recursive=True)

        # æ’é™¤.cleanupç›®å½•ä¸­çš„æ–‡ä»¶ (è™½ç„¶globåº”è¯¥ä¸ä¼šæ‰«åˆ°ï¼Œä½†ä¸ºäº†ä¿é™©)
        files = [f for f in files if CLEANUP_ROOT not in f]

        print(f"Found {len(files)} XML files in {BLUEPRINTS_DIR}")
        return files

    def scan_all_files(self):
        """æ‰«ææ‰€æœ‰ç›¸å…³æ–‡ä»¶ï¼ˆXML + PNG + Minimapï¼‰"""
        xml_files = self.scan_local_files()

        # æ‰«æå›¾ç‰‡æ–‡ä»¶
        images_dir = "images"
        png_files = glob.glob(os.path.join(images_dir, "*.png"))
        jpg_files = glob.glob(os.path.join(images_dir, "*.jpg"))

        # æ’é™¤.cleanupç›®å½•
        image_files = [f for f in png_files + jpg_files if CLEANUP_ROOT not in f]

        print(f"Found {len(image_files)} image files")

        return xml_files, image_files

    def extract_blueprint_id(self, file_path):
        """ä»XMLæ–‡ä»¶ä¸­æå–blueprint ID"""
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()

            extra_info = root.find("extraInfo")
            if extra_info is not None:
                building_id_elem = extra_info.find("BuildingID")
                if building_id_elem is not None and building_id_elem.text:
                    return building_id_elem.text.strip()

            return None
        except Exception as e:
            print(f"Error parsing {file_path}: {e}")
            return None

    def identify_orphaned_files(self, valid_ids):
        """è¯†åˆ«å­¤å„¿æ–‡ä»¶ç»„"""
        xml_files, image_files = self.scan_all_files()

        valid_groups = []
        orphaned_groups = []

        processed_ids = set()

        for xml_file in xml_files:
            blueprint_id = self.extract_blueprint_id(xml_file)

            if not blueprint_id:
                print(f"âš ï¸  {xml_file}: No blueprint ID found")
                continue

            if blueprint_id in processed_ids:
                continue

            processed_ids.add(blueprint_id)

            if blueprint_id in valid_ids:
                valid_group = self.find_related_files(blueprint_id)
                if valid_group['xml']:  # åªæœ‰æ‰¾åˆ°XMLæ‰ç®—æœ‰æ•ˆ
                    valid_groups.append(valid_group)
            else:
                orphaned_group = self.find_related_files(blueprint_id)
                if orphaned_group['xml']:  # åªæœ‰æ‰¾åˆ°XMLæ‰ç®—å­¤å„¿
                    orphaned_groups.append(orphaned_group)

        return valid_groups, orphaned_groups

    def find_related_files(self, blueprint_id):
        """æŸ¥æ‰¾ä¸blueprint IDç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶"""
        related_files = {
            'blueprint_id': blueprint_id,
            'xml': None,
            'png': None,
            'minimap_png': None,
            'minimap_jpg': None,
            'total_size': 0
        }

        # æŸ¥æ‰¾XMLæ–‡ä»¶
        xml_files = self.scan_local_files()
        for xml_file in xml_files:
            if self.extract_blueprint_id(xml_file) == blueprint_id:
                related_files['xml'] = xml_file
                if os.path.exists(xml_file):
                    related_files['total_size'] += os.path.getsize(xml_file)
                break

        if related_files['xml']:
            # åŸºäºXMLæ–‡ä»¶åæŸ¥æ‰¾ç›¸å…³å›¾ç‰‡
            base_name = os.path.splitext(os.path.basename(related_files['xml']))[0]

            # ä¸»å›¾ç‰‡
            png_path = os.path.join("images", f"{base_name}.png")
            if os.path.exists(png_path):
                related_files['png'] = png_path
                related_files['total_size'] += os.path.getsize(png_path)

            # å°åœ°å›¾
            minimap_png_path = os.path.join("images", f"{base_name}_minimap.png")
            if os.path.exists(minimap_png_path):
                related_files['minimap_png'] = minimap_png_path
                related_files['total_size'] += os.path.getsize(minimap_png_path)

            minimap_jpg_path = os.path.join("images", f"{base_name}_minimap.jpg")
            if os.path.exists(minimap_jpg_path):
                related_files['minimap_jpg'] = minimap_jpg_path
                related_files['total_size'] += os.path.getsize(minimap_jpg_path)

        return related_files

    def move_blueprint_group(self, blueprint_group, dry_run=True):
        """ç§»åŠ¨å®Œæ•´çš„è“å›¾æ–‡ä»¶ç»„åˆ°.cleanupç›®å½•"""
        
        if not dry_run:
            os.makedirs(CLEANUP_BLUEPRINTS_DIR, exist_ok=True)
            os.makedirs(CLEANUP_IMAGES_DIR, exist_ok=True)

        moved_files = []

        # ç§»åŠ¨XMLæ–‡ä»¶
        if blueprint_group['xml'] and os.path.exists(blueprint_group['xml']):
            xml_dest = os.path.join(CLEANUP_BLUEPRINTS_DIR, os.path.basename(blueprint_group['xml']))
            if dry_run:
                print(f"  Would move XML: {blueprint_group['xml']} -> {xml_dest}")
                moved_files.append(blueprint_group['xml'])
            else:
                try:
                    os.makedirs(os.path.dirname(xml_dest), exist_ok=True)
                    os.rename(blueprint_group['xml'], xml_dest)
                    print(f"  Moved XML: {xml_dest}")
                    moved_files.append(xml_dest)
                except Exception as e:
                    print(f"  Failed to move XML {blueprint_group['xml']}: {e}")

        # ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶
        for image_key in ['png', 'minimap_png', 'minimap_jpg']:
            image_file = blueprint_group[image_key]
            if image_file and os.path.exists(image_file):
                image_dest = os.path.join(CLEANUP_IMAGES_DIR, os.path.basename(image_file))
                if dry_run:
                    print(f"  Would move {image_key}: {image_file} -> {image_dest}")
                    moved_files.append(image_file)
                else:
                    try:
                        os.makedirs(os.path.dirname(image_dest), exist_ok=True)
                        os.rename(image_file, image_dest)
                        print(f"  Moved {image_key}: {image_dest}")
                        moved_files.append(image_dest)
                    except Exception as e:
                        print(f"  Failed to move {image_key} {image_file}: {e}")

        return moved_files

    def delete_file(self, file_path, dry_run=True):
        """åˆ é™¤æ–‡ä»¶ï¼ˆåŒ…æ‹¬ç›¸å…³å›¾ç‰‡æ–‡ä»¶ï¼‰"""
        base_name = os.path.splitext(file_path)[0]

        files_to_delete = [
            file_path,  # .xmlæ–‡ä»¶
            f"{base_name}.png",  # ä¸»å›¾ç‰‡
            f"{base_name}_minimap.png",  # å°åœ°å›¾
            f"{base_name}_minimap.jpg"  # å°åœ°å›¾ï¼ˆjpgæ ¼å¼ï¼‰
        ]

        deleted_files = []
        for f in files_to_delete:
            if os.path.exists(f):
                if dry_run:
                    print(f"  Would delete: {f}")
                    deleted_files.append(f)
                else:
                    try:
                        os.remove(f)
                        print(f"  Deleted: {f}")
                        deleted_files.append(f)
                    except Exception as e:
                        print(f"  Failed to delete {f}: {e}")

        return deleted_files

    def cleanup_orphaned_files(self, dry_run=True, auto_delete=False):
        """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
        print("=== Orphaned Files Cleanup ===")
        print(f"Dry run: {dry_run}")
        print(f"Auto delete: {auto_delete}")
        print()

        # 0. å…ˆæ¸…ç†è¿‡æœŸçš„å¤‡ä»½æ–‡ä»¶ (åœ¨æ‰€æœ‰æ“ä½œä¹‹å‰)
        self.prune_old_cleanup_files(dry_run=dry_run)

        # 1. è·å–æœ‰æ•ˆçš„blueprint IDåˆ—è¡¨
        valid_ids = self.get_valid_blueprint_ids()
        if valid_ids is None:
            print("Failed to get valid blueprint IDs from database")
            return False

        # 2. è¯†åˆ«å­¤å„¿æ–‡ä»¶ç»„
        valid_groups, orphaned_groups = self.identify_orphaned_files(valid_ids)

        total_orphaned_files = sum(
            1 for group in orphaned_groups
            for key in ['xml', 'png', 'minimap_png', 'minimap_jpg']
            if group[key] is not None
        )

        print(f"Valid blueprint groups: {len(valid_groups)}")
        print(f"Orphaned blueprint groups: {len(orphaned_groups)}")
        print(f"Total orphaned files: {total_orphaned_files}")
        print()

        if not orphaned_groups:
            print("âœ… No orphaned blueprint groups found!")
            # å³ä½¿æ²¡æœ‰å­¤å„¿æ–‡ä»¶ï¼Œå¦‚æœæœ‰ dry_run=Falseï¼Œæˆ‘ä»¬å¯èƒ½å·²ç»æ‰§è¡Œäº† prune_old_cleanup_files
            return True

        # 4. æ˜¾ç¤ºå­¤å„¿æ–‡ä»¶ä¿¡æ¯
        total_size = sum(group['total_size'] for group in orphaned_groups)
        print("ğŸ” Orphaned blueprint groups found:")
        for i, group in enumerate(orphaned_groups, 1):
            file_count = sum(1 for key in ['xml', 'png', 'minimap_png', 'minimap_jpg']
                           if group[key] is not None)
            print(f"  {i}. {group['blueprint_id']} - {file_count} files, {group['total_size']} bytes")

        print(f"\nTotal space to be freed: {total_size} bytes ({total_size / 1024 / 1024:.2f} MB)")
        print()

        # 5. å¤„ç†æ¸…ç†æ“ä½œ
        should_cleanup = False
        if auto_delete:
            should_cleanup = True
        elif not dry_run:
            if sys.stdin.isatty():
                should_cleanup = input("Cleanup these orphaned files? (y/N): ").lower() == 'y'
            else:
                print("âš ï¸  Non-interactive mode detected without --auto-delete. Skipping cleanup check.")
                should_cleanup = False
        
        if should_cleanup:
            strategy = 'move' # é»˜è®¤ç­–ç•¥
            
            if auto_delete:
                print("ğŸ¤– Auto cleanup mode - Moving files to .cleanup directory")
                strategy = 'move'
            elif not dry_run and sys.stdin.isatty():
                user_strategy = input("Choose cleanup strategy (move/delete/backup): ").lower()
                if user_strategy in ['move', 'delete', 'backup']:
                    strategy = user_strategy
            else:
                print("ğŸ¤– Non-interactive mode - Defaulting to 'move' strategy")

            if strategy in ['move', 'backup'] or auto_delete:
                print(f"ğŸ“¦ Moving orphaned blueprint groups to {CLEANUP_ROOT} directory...")
                total_moved = []

                for group in orphaned_groups:
                    print(f"\nProcessing group: {group['blueprint_id']}")
                    moved = self.move_blueprint_group(group, dry_run=False)
                    total_moved.extend(moved)

                print(f"\nâœ… Moved {len(total_moved)} files to {CLEANUP_ROOT} directory")

                # 6. æ¸…ç†åé‡æ–°ç”Ÿæˆindex
                if not dry_run:
                    print("\nğŸ”„ Regenerating index after cleanup...")
                    self.regenerate_index_after_cleanup()

            elif strategy == 'delete':
                print("ğŸ—‘ï¸  Permanently deleting orphaned files...")
                total_deleted = []

                for group in orphaned_groups:
                    print(f"\nProcessing group: {group['blueprint_id']}")
                    if group['xml']:
                        deleted = self.delete_file(group['xml'], dry_run=False)
                        total_deleted.extend(deleted)

                print(f"\nâœ… Deleted {len(total_deleted)} files permanently")

                # 6. æ¸…ç†åé‡æ–°ç”Ÿæˆindex
                if not dry_run:
                    print("\nğŸ”„ Regenerating index after cleanup...")
                    self.regenerate_index_after_cleanup()
        else:
            print("ğŸ“‹ Cleanup cancelled (dry run or user declined)")

        # 7. ç”ŸæˆæŠ¥å‘Š
        self.generate_cleanup_report(valid_groups, orphaned_groups, dry_run)

        return True

    def regenerate_index_after_cleanup(self):
        """æ¸…ç†åé‡æ–°ç”Ÿæˆindex.json"""
        try:
            print("Running generate_index.py...")
            result = subprocess.run(
                ['python', 'scripts/generate_index.py'],
                capture_output=True,
                text=True,
                check=False
            )

            if result.returncode == 0:
                print("âœ… Index regenerated successfully")
                print("Output:", result.stdout)
            else:
                print("âŒ Index regeneration failed")
                print("Error:", result.stderr)
        except Exception as e:
            print(f"âŒ Failed to regenerate index: {e}")

    def generate_cleanup_report(self, valid_files, orphaned_files, dry_run):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Šï¼Œä¿å­˜åˆ° .cleanup/reports"""
        report_data = {
            "cleanup_timestamp": datetime.datetime.utcnow().isoformat() + "Z",
            "dry_run": dry_run,
            "statistics": {
                "total_files_scanned": len(valid_files) + len(orphaned_files),
                "valid_files": len(valid_files),
                "orphaned_files": len(orphaned_files)
            },
            "orphaned_files": orphaned_files,
            "valid_files_count": len(valid_files)
        }

        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        if not dry_run:
            os.makedirs(CLEANUP_REPORTS_DIR, exist_ok=True)
            filename_base = os.path.join(CLEANUP_REPORTS_DIR, f"cleanup_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        else:
            # Dry run æ¨¡å¼ä¸‹ä¸åˆ›å»ºç›®å½•ï¼Œåªæ‰“å°æ–‡ä»¶å
            filename_base = f"cleanup_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        if not dry_run:
            try:
                with open(filename_base, 'w', encoding='utf-8') as f:
                    json.dump(report_data, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ“„ Report generated: {filename_base}")
            except Exception as e:
                print(f"\nâŒ Failed to generate report: {e}")
        else:
            print(f"\nğŸ“„ [Dry Run] Report would be generated at: {filename_base}")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
        print("é”™è¯¯: ç¼ºå°‘SUPABASE_URLæˆ–SUPABASE_SERVICE_KEYç¯å¢ƒå˜é‡")
        sys.exit(1)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    dry_run = True  # é»˜è®¤æ˜¯å¹²è¿è¡Œ
    auto_delete = False
    
    # æ£€æŸ¥æ˜¯å¦åœ¨ CI ç¯å¢ƒä¸­ (GitHub Actions ä¼šè®¾ç½® CI=true)
    is_ci_env = os.environ.get('CI', 'false').lower() == 'true' or not sys.stdin.isatty()

    if "--execute" in sys.argv:
        dry_run = False
        print("ğŸš¨ æ‰§è¡Œæ¨¡å¼ - å°†å®é™…å¤„ç†æ–‡ä»¶!")
        
        # å¦‚æœæ˜¯åœ¨ CI/æ— äº¤äº’ç¯å¢ƒä¸‹ç”¨äº† --executeï¼Œå¼ºåˆ¶å¼€å¯è‡ªåŠ¨åˆ é™¤æ¨¡å¼
        if is_ci_env:
            print("ğŸ¤– æ£€æµ‹åˆ°æ— äº¤äº’ç¯å¢ƒ (CI/GitHub Actions)ã€‚å°† --execute è§†ä¸º --auto-deleteã€‚")
            auto_delete = True

    if "--auto-delete" in sys.argv:
        auto_delete = True
        dry_run = False
        print("ğŸ¤– è‡ªåŠ¨åˆ é™¤æ¨¡å¼ - å°†ç§»åŠ¨/åˆ é™¤æ‰€æœ‰å­¤å„¿æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½!")

    # ç¡®è®¤å±é™©æ“ä½œ
    if not dry_run and not auto_delete:
        if sys.stdin.isatty():
            print("âš ï¸  è¿™å°†å®é™…åˆ é™¤æ–‡ä»¶! è¯·ç¡®ä¿ä½ æœ‰å¤‡ä»½ã€‚")
            try:
                if input("ç»§ç»­æ‰§è¡Œ? (yes/no): ").lower() != 'yes':
                    print("æ“ä½œå·²å–æ¶ˆ")
                    sys.exit(0)
            except EOFError:
                print("âŒ æ— æ³•è¯»å–è¾“å…¥ (EOF)ã€‚è¯·ä½¿ç”¨ --auto-delete å‚æ•°è·³è¿‡ç¡®è®¤ã€‚")
                sys.exit(1)
        else:
            print("âŒ éäº¤äº’ç¯å¢ƒä¸èƒ½ç­‰å¾…è¾“å…¥ã€‚è¯·ä½¿ç”¨ --auto-delete å‚æ•°ã€‚")
            sys.exit(1)

    # æ‰§è¡Œæ¸…ç†
    cleaner = OrphanedFileCleaner(SUPABASE_URL, SUPABASE_SERVICE_KEY)
    success = cleaner.cleanup_orphaned_files(dry_run=dry_run, auto_delete=auto_delete)

    if success:
        print("\nâœ… Cleanup completed successfully")
        sys.exit(0)
    else:
        print("\nâŒ Cleanup failed")
        sys.exit(1)

if __name__ == "__main__":
    main()